from hazm import word_tokenize

def tokenize(text: str) -> list[str]:
    return word_tokenize(text)
